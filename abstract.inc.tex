\chapter*{Abstract}

This thesis investigates single image depth estimation (SIDE), an important computer vision task with critical applications in autonomous driving and robotics, and explores its interpretability.
SIDE tackles the challenge of reconstructing the geometric structure of a scene from a single image by assigning a depth value to each pixel, corresponding to the depth of the object represented by that pixel within the camera's coordinate system.
Specifically, SIDE can be decomposed into two primary sub-tasks: (1) estimating depth maps for image patches and (2) merging these depth maps to produce a comprehensive depth prediction.

A significant challenge with deep learning models is their nature as black boxes, which means they lack transparency and are not easily interpretable by humans.
Currently, all state-of-the-art approaches in SIDE exhibit this black-box characteristic.
It is argued that there are inherent limitations to the interpretability of algorithms for tasks like SIDE, which necessitates the use of black-box components to achieve effective solutions.
These limitations arise from the inability of current methods to fully capture the complexity of human cognition.

To develop more interpretable methods, this thesis also explores alternative approaches to defining the first sub-task, aiming to simplify it from a statistical learning perspective.
This simplification requires an effective merging procedure to complete the depth map.
Ultimately, a novel interpretable depth fusion procedure is proposed to address these challenges.

\thispagestyle{empty}
\mbox{}
\newpage
